{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:27: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and preprocess data\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder, GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idML</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>geo</th>\n",
       "      <th>noc_code</th>\n",
       "      <th>noc_desc</th>\n",
       "      <th>job_char</th>\n",
       "      <th>total_vacancies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>46138232.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>5795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>46138235.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>4695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>46138238.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>46139695.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>46139698.0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Business, finance and administration occupations</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10708</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>152495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10709</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Total, all occupations</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>621080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10710</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>105530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10711</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>8695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10712</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trades, transport and equipment operators and ...</td>\n",
       "      <td>Type of work, all types</td>\n",
       "      <td>114440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1847 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             idML   ref_date                        geo  noc_code  \\\n",
       "7932   46138232.0 2023-01-01  Newfoundland and Labrador     101.0   \n",
       "7933   46138235.0 2023-01-01  Newfoundland and Labrador     101.0   \n",
       "7934   46138238.0 2023-01-01  Newfoundland and Labrador     101.0   \n",
       "7935   46139695.0 2023-01-01  Newfoundland and Labrador       1.0   \n",
       "7936   46139698.0 2023-01-01  Newfoundland and Labrador       1.0   \n",
       "...           ...        ...                        ...       ...   \n",
       "10708         NaN 2024-01-04                     Canada       NaN   \n",
       "10709         NaN 2024-01-04                     Canada       NaN   \n",
       "10710         NaN 2024-01-04                     Canada       NaN   \n",
       "10711         NaN 2024-01-04                     Canada       NaN   \n",
       "10712         NaN 2024-01-04                     Canada       NaN   \n",
       "\n",
       "                                                noc_desc  \\\n",
       "7932                              Total, all occupations   \n",
       "7933                              Total, all occupations   \n",
       "7934                              Total, all occupations   \n",
       "7935    Business, finance and administration occupations   \n",
       "7936    Business, finance and administration occupations   \n",
       "...                                                  ...   \n",
       "10708                             Total, all occupations   \n",
       "10709                             Total, all occupations   \n",
       "10710  Trades, transport and equipment operators and ...   \n",
       "10711  Trades, transport and equipment operators and ...   \n",
       "10712  Trades, transport and equipment operators and ...   \n",
       "\n",
       "                      job_char  total_vacancies  \n",
       "7932   Type of work, all types             5795  \n",
       "7933                 Full-time             4695  \n",
       "7934                 Part-time             1095  \n",
       "7935   Type of work, all types              780  \n",
       "7936                 Full-time              710  \n",
       "...                        ...              ...  \n",
       "10708                Part-time           152495  \n",
       "10709  Type of work, all types           621080  \n",
       "10710                Full-time           105530  \n",
       "10711                Part-time             8695  \n",
       "10712  Type of work, all types           114440  \n",
       "\n",
       "[1847 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load and preprocess data\n",
    "data = pd.read_csv('D:/MAC-Course/Sem 2/ADT/Final Project/Predicting_Canadian_Job_Vacancies-main/Predicting_Canadian_Job_Vacancies-main/Database/Resources/MachineLearning.csv')\n",
    "data['ref_date'] = pd.to_datetime(data['ref_date'], format='%m-%d-%Y')\n",
    "\n",
    "# Remove existing 'Canada' entries\n",
    "data = data[data['geo'] != 'Canada']\n",
    "\n",
    "# Aggregate total vacancies over provinces to compute 'Canada' totals\n",
    "canada_totals = data.groupby(['ref_date', 'noc_desc', 'job_char'], as_index=False)['total_vacancies'].sum()\n",
    "\n",
    "# Add 'geo' column with value 'Canada'\n",
    "canada_totals['geo'] = 'Canada'\n",
    "\n",
    "# Append 'Canada' totals back into the data\n",
    "data = pd.concat([data, canada_totals], ignore_index=True)\n",
    "\n",
    "# Now proceed with filtering data for training (2015-2022) and future prediction (2023-2024)\n",
    "train_data = data[(data['ref_date'] >= '2019-01-01') & (data['ref_date'] <= '2022-12-31')]\n",
    "future_data = data[(data['ref_date'] >= '2023-01-01') & (data['ref_date'] <= '2024-12-31')]\n",
    "# Extend future data for years 2025-2027\n",
    "future_dates = pd.date_range(start=\"2025-01-01\", end=\"2027-12-31\", freq=\"QS\")  # Quarterly Start\n",
    "\n",
    "future_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training data: 4364\n",
      "Number of rows in future data: 1847\n",
      "Unique provinces in training data: ['Newfoundland and Labrador' 'Prince Edward Island' 'Nova Scotia'\n",
      " 'New Brunswick' 'Quebec' 'Ontario' 'Manitoba' 'Saskatchewan' 'Alberta'\n",
      " 'British Columbia' 'Yukon' 'Northwest Territories' 'Nunavut' 'Canada']\n",
      "Unique provinces in future data: ['Newfoundland and Labrador' 'Prince Edward Island' 'Nova Scotia'\n",
      " 'New Brunswick' 'Quebec' 'Ontario' 'Manitoba' 'Saskatchewan' 'Alberta'\n",
      " 'British Columbia' 'Yukon' 'Northwest Territories' 'Nunavut' 'Canada']\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows in the training and future data\n",
    "print(f\"Number of rows in training data: {len(train_data)}\")\n",
    "print(f\"Number of rows in future data: {len(future_data)}\")\n",
    "\n",
    "# Check unique provinces in the training data\n",
    "print(f\"Unique provinces in training data: {train_data['geo'].unique()}\")\n",
    "\n",
    "# Check unique provinces in the future data\n",
    "print(f\"Unique provinces in future data: {future_data['geo'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in future data:\n",
      "idML               190\n",
      "ref_date             0\n",
      "geo                  0\n",
      "noc_code           190\n",
      "noc_desc             0\n",
      "job_char             0\n",
      "total_vacancies      0\n",
      "dtype: int64\n",
      "Date range in future data: 2023-01-01 00:00:00 to 2024-01-04 00:00:00\n",
      "Unique combinations in training data: 402\n",
      "Unique combinations in future data: 368\n",
      "Missing combinations in future data:\n",
      "                       geo                                           noc_desc  \\\n",
      "77           New Brunswick         Occupations in manufacturing and utilities   \n",
      "104                 Quebec  Natural resources, agriculture and related pro...   \n",
      "113                Ontario      Legislative and senior management occupations   \n",
      "145               Manitoba      Legislative and senior management occupations   \n",
      "165               Manitoba         Occupations in manufacturing and utilities   \n",
      "252                  Yukon                                 Health occupations   \n",
      "263  Northwest Territories                      Sales and service occupations   \n",
      "264  Northwest Territories  Natural resources, agriculture and related pro...   \n",
      "265  Northwest Territories  Natural resources, agriculture and related pro...   \n",
      "273                Nunavut  Occupations in education, law and social, comm...   \n",
      "274                Nunavut  Occupations in education, law and social, comm...   \n",
      "275                Nunavut  Occupations in education, law and social, comm...   \n",
      "281                Nunavut  Trades, transport and equipment operators and ...   \n",
      "289            Nova Scotia  Occupations in art, culture, recreation and sport   \n",
      "290          New Brunswick      Legislative and senior management occupations   \n",
      "291          New Brunswick      Legislative and senior management occupations   \n",
      "301           Saskatchewan         Occupations in manufacturing and utilities   \n",
      "307                  Yukon  Occupations in art, culture, recreation and sport   \n",
      "308                  Yukon                      Sales and service occupations   \n",
      "309  Northwest Territories   Business, finance and administration occupations   \n",
      "310  Northwest Territories                                 Health occupations   \n",
      "317            Nova Scotia  Natural and applied sciences and related occup...   \n",
      "318            Nova Scotia  Occupations in art, culture, recreation and sport   \n",
      "319          New Brunswick  Occupations in art, culture, recreation and sport   \n",
      "320               Manitoba      Legislative and senior management occupations   \n",
      "327                Nunavut  Natural resources, agriculture and related pro...   \n",
      "328                Nunavut  Natural resources, agriculture and related pro...   \n",
      "338                Nunavut         Occupations in manufacturing and utilities   \n",
      "339                Nunavut         Occupations in manufacturing and utilities   \n",
      "345           Saskatchewan      Legislative and senior management occupations   \n",
      "346       British Columbia  Natural and applied sciences and related occup...   \n",
      "347  Northwest Territories  Occupations in education, law and social, comm...   \n",
      "350            Nova Scotia         Occupations in manufacturing and utilities   \n",
      "351          New Brunswick  Natural and applied sciences and related occup...   \n",
      "352                 Quebec      Legislative and senior management occupations   \n",
      "355       British Columbia      Legislative and senior management occupations   \n",
      "356                  Yukon  Occupations in education, law and social, comm...   \n",
      "359  Northwest Territories  Natural and applied sciences and related occup...   \n",
      "361                Alberta  Natural resources, agriculture and related pro...   \n",
      "363       British Columbia  Natural resources, agriculture and related pro...   \n",
      "364                  Yukon  Trades, transport and equipment operators and ...   \n",
      "366            Nova Scotia      Legislative and senior management occupations   \n",
      "376                 Canada      Legislative and senior management occupations   \n",
      "\n",
      "                    job_char     _merge  \n",
      "77                 Part-time  left_only  \n",
      "104                Part-time  left_only  \n",
      "113                Part-time  left_only  \n",
      "145                Full-time  left_only  \n",
      "165                Part-time  left_only  \n",
      "252                Full-time  left_only  \n",
      "263                Part-time  left_only  \n",
      "264  Type of work, all types  left_only  \n",
      "265                Full-time  left_only  \n",
      "273  Type of work, all types  left_only  \n",
      "274                Full-time  left_only  \n",
      "275                Part-time  left_only  \n",
      "281                Part-time  left_only  \n",
      "289  Type of work, all types  left_only  \n",
      "290  Type of work, all types  left_only  \n",
      "291                Full-time  left_only  \n",
      "301                Part-time  left_only  \n",
      "307                Part-time  left_only  \n",
      "308                Part-time  left_only  \n",
      "309                Part-time  left_only  \n",
      "310                Part-time  left_only  \n",
      "317                Part-time  left_only  \n",
      "318                Full-time  left_only  \n",
      "319                Part-time  left_only  \n",
      "320                Part-time  left_only  \n",
      "327  Type of work, all types  left_only  \n",
      "328                Full-time  left_only  \n",
      "338  Type of work, all types  left_only  \n",
      "339                Full-time  left_only  \n",
      "345                Part-time  left_only  \n",
      "346                Part-time  left_only  \n",
      "347                Part-time  left_only  \n",
      "350                Part-time  left_only  \n",
      "351                Part-time  left_only  \n",
      "352                Part-time  left_only  \n",
      "355                Part-time  left_only  \n",
      "356                Part-time  left_only  \n",
      "359                Part-time  left_only  \n",
      "361                Part-time  left_only  \n",
      "363                Part-time  left_only  \n",
      "364                Part-time  left_only  \n",
      "366                Part-time  left_only  \n",
      "376                Part-time  left_only  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the future data\n",
    "print(f\"Missing values in future data:\\n{future_data.isnull().sum()}\")\n",
    "\n",
    "# Check the date range in the future data\n",
    "print(f\"Date range in future data: {future_data['ref_date'].min()} to {future_data['ref_date'].max()}\")\n",
    "\n",
    "# Check unique combinations of geo, noc_desc, and job_char in training data\n",
    "train_combinations = train_data[['geo', 'noc_desc', 'job_char']].drop_duplicates()\n",
    "print(f\"Unique combinations in training data: {len(train_combinations)}\")\n",
    "\n",
    "# Check unique combinations of geo, noc_desc, and job_char in future data\n",
    "future_combinations = future_data[['geo', 'noc_desc', 'job_char']].drop_duplicates()\n",
    "print(f\"Unique combinations in future data: {len(future_combinations)}\")\n",
    "# Find missing combinations in future data\n",
    "missing_combinations = pd.merge(train_combinations, future_combinations, on=['geo', 'noc_desc', 'job_char'], how='left', indicator=True)\n",
    "missing_combinations = missing_combinations[missing_combinations['_merge'] == 'left_only']\n",
    "print(f\"Missing combinations in future data:\\n{missing_combinations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all combinations of geo, noc_desc, and job_char for future dates\n",
    "geo_values = train_data['geo'].unique()\n",
    "noc_desc_values = train_data['noc_desc'].unique()\n",
    "job_char_values = train_data['job_char'].unique()\n",
    "\n",
    "future_combinations = pd.DataFrame(\n",
    "    list(product(future_dates, geo_values, noc_desc_values, job_char_values)),\n",
    "    columns=[\"ref_date\", \"geo\", \"noc_desc\", \"job_char\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add placeholder for total_vacancies in the extended future data\n",
    "future_combinations['total_vacancies'] = None\n",
    "\n",
    "# Combine with existing future data\n",
    "future_data = pd.concat([future_data, future_combinations], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training data: 4364\n",
      "Number of rows in future data (2023-2027): 7391\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows in the training and future data\n",
    "print(f\"Number of rows in training data: {len(train_data)}\")\n",
    "print(f\"Number of rows in future data (2023-2027): {len(future_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_22552\\3534478187.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['total_vacancies_scaled'] = scaler.transform(train_data[['total_vacancies']])\n",
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_22552\\3534478187.py:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  future_data['total_vacancies_scaled'] = scaler.transform(future_data[['total_vacancies']].fillna(0))  # Replace NaNs with 0 for scaling\n",
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_22552\\3534478187.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['geo_encoded'] = geo_encoder.fit_transform(train_data['geo'])\n",
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_22552\\3534478187.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['noc_desc_encoded'] = sector_encoder.fit_transform(train_data['noc_desc'])\n",
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_22552\\3534478187.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['job_char_encoded'] = job_char_encoder.fit_transform(train_data['job_char'])\n",
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_22552\\3534478187.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['time_idx'] = (train_data['ref_date'] - train_data['ref_date'].min()).dt.days\n"
     ]
    }
   ],
   "source": [
    "# Fit the scaler on the entire `total_vacancies` column to ensure all ranges are covered.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[['total_vacancies']])\n",
    "\n",
    "# Apply scaling to train and future data\n",
    "train_data['total_vacancies_scaled'] = scaler.transform(train_data[['total_vacancies']])\n",
    "future_data['total_vacancies_scaled'] = scaler.transform(future_data[['total_vacancies']].fillna(0))  # Replace NaNs with 0 for scaling\n",
    "\n",
    "# Encode categorical columns\n",
    "geo_encoder = NaNLabelEncoder()\n",
    "sector_encoder = NaNLabelEncoder()\n",
    "job_char_encoder = NaNLabelEncoder()\n",
    "\n",
    "train_data['geo_encoded'] = geo_encoder.fit_transform(train_data['geo'])\n",
    "train_data['noc_desc_encoded'] = sector_encoder.fit_transform(train_data['noc_desc'])\n",
    "train_data['job_char_encoded'] = job_char_encoder.fit_transform(train_data['job_char'])\n",
    "\n",
    "future_data['geo_encoded'] = geo_encoder.transform(future_data['geo'])\n",
    "future_data['noc_desc_encoded'] = sector_encoder.transform(future_data['noc_desc'])\n",
    "future_data['job_char_encoded'] = job_char_encoder.transform(future_data['job_char'])\n",
    "\n",
    "# Create a time index\n",
    "train_data['time_idx'] = (train_data['ref_date'] - train_data['ref_date'].min()).dt.days\n",
    "future_data['time_idx'] = (future_data['ref_date'] - train_data['ref_date'].min()).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers using the interquartile range (IQR)\n",
    "q1 = train_data['total_vacancies'].quantile(0.25)\n",
    "q3 = train_data['total_vacancies'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Define acceptable range\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Filter out outliers\n",
    "train_data = train_data[(train_data['total_vacancies'] >= lower_bound) & (train_data['total_vacancies'] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py:1301: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 55 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__geo_encoded': 0, '__group_id__noc_desc_encoded': 4, '__group_id__job_char_encoded': 1}, {'__group_id__geo_encoded': 0, '__group_id__noc_desc_encoded': 7, '__group_id__job_char_encoded': 1}, {'__group_id__geo_encoded': 1, '__group_id__noc_desc_encoded': 2, '__group_id__job_char_encoded': 1}, {'__group_id__geo_encoded': 1, '__group_id__noc_desc_encoded': 3, '__group_id__job_char_encoded': 1}, {'__group_id__geo_encoded': 1, '__group_id__noc_desc_encoded': 4, '__group_id__job_char_encoded': 1}, {'__group_id__geo_encoded': 1, '__group_id__noc_desc_encoded': 7, '__group_id__job_char_encoded': 1}, {'__group_id__geo_encoded': 2, '__group_id__noc_desc_encoded': 7, '__group_id__job_char_encoded': 2}, {'__group_id__geo_encoded': 3, '__group_id__noc_desc_encoded': 3, '__group_id__job_char_encoded': 1}, {'__group_id__geo_encoded': 4, '__group_id__noc_desc_encoded': 2, '__group_id__job_char_encoded': 0}, {'__group_id__geo_encoded': 4, '__group_id__noc_desc_encoded': 2, '__group_id__job_char_encoded': 2}]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define TimeSeriesDataSet\n",
    "max_encoder_length = 120\n",
    "max_prediction_length = 30\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"total_vacancies_scaled\",\n",
    "    group_ids=[\"geo_encoded\", \"noc_desc_encoded\", \"job_char_encoded\"],\n",
    "    min_encoder_length=1,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"geo\", \"noc_desc\", \"job_char\"],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_reals=[\"total_vacancies_scaled\"],\n",
    "    categorical_encoders={\n",
    "        \"geo_encoded\": NaNLabelEncoder(),\n",
    "        \"noc_desc_encoded\": NaNLabelEncoder(),\n",
    "        \"job_char_encoded\": NaNLabelEncoder()\n",
    "    },\n",
    "    target_normalizer=GroupNormalizer(groups=[\"geo_encoded\", \"noc_desc_encoded\", \"job_char_encoded\"]),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in train_dataset: 6\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows in the train_dataset\n",
    "print(f\"Number of rows in train_dataset: {len(train_dataset.data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = train_dataset.to_dataloader(train=True, batch_size=64, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "val_loader = train_dataset.to_dataloader(train=False, batch_size=64, num_workers=4, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x155854de570>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader\n",
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type                      | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | tft  | TemporalFusionTransformer | 262 K  | train\n",
      "-----------------------------------------------------------\n",
      "262 K     Trainable params\n",
      "0         Non-trainable params\n",
      "262 K     Total params\n",
      "1.050     Total estimated model params size (MB)\n",
      "303       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:08<00:00,  8.62it/s, v_num=164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "Metric val_loss improved. New best score: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:08<00:00,  8.14it/s, v_num=164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:08<00:00,  8.74it/s, v_num=164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.001. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:08<00:00,  8.68it/s, v_num=164]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "\n",
    "\n",
    "# Define and train Temporal Fusion Transformer\n",
    "class TFTModule(LightningModule):\n",
    "\tdef __init__(self, tft):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.tft = tft\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\ty_pred = self.tft(x)\n",
    "\t\t# Ensure y_pred has the correct shape\n",
    "\t\tif isinstance(y_pred, tuple):\n",
    "\t\t\ty_pred = y_pred[0]\n",
    "\t\treturn y_pred\n",
    "\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tx, y = batch\n",
    "\t\ty_hat = self(x)\n",
    "\t\tloss = self.tft.loss(y_hat, y)\n",
    "\t\tself.log(\"train_loss\", loss)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef validation_step(self, batch, batch_idx):\n",
    "\t\tx, y = batch\n",
    "\t\ty_hat = self(x)\n",
    "\t\tloss = self.tft.loss(y_hat, y)\n",
    "\t\tself.log(\"val_loss\", loss)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "\t\treturn torch.optim.Adam(self.parameters(), lr=0.03)\n",
    "\n",
    "\n",
    "tft = TFTModule(TemporalFusionTransformer.from_dataset(\n",
    "\ttrain_dataset,\n",
    "\tlearning_rate=0.001,\n",
    "\thidden_size=64,\n",
    "\tattention_head_size=8,\n",
    "\tdropout=0.1,\n",
    "\thidden_continuous_size=32,\n",
    "\toutput_size=len(QuantileLoss().quantiles),  # QuantileLoss output size\n",
    "\tloss=QuantileLoss(),\n",
    "\toptimizer=\"adam\",\n",
    "\tlog_interval=10\n",
    "))\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=True, mode=\"min\", min_delta=1e-4)\n",
    "trainer = Trainer(\n",
    "\tmax_epochs=100,  # Increased number of epochs\n",
    "\taccelerator=\"cpu\",\n",
    "\tdevices=1,\n",
    "\tcallbacks=[early_stop_callback]\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(tft, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_22552\\2098269465.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['total_vacancies_scaled'].fillna(combined_data['total_vacancies_scaled'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare future data for prediction\n",
    "combined_data = pd.concat([train_data, future_data]).drop_duplicates(subset=['time_idx', 'geo_encoded', 'noc_desc_encoded', 'job_char_encoded'])\n",
    "combined_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Fill missing values in total_vacancies_scaled with the mean of the column\n",
    "combined_data['total_vacancies_scaled'].fillna(combined_data['total_vacancies_scaled'].mean(), inplace=True)\n",
    "\n",
    "combined_dataset = TimeSeriesDataSet.from_dataset(train_dataset, combined_data)\n",
    "dataloader = combined_dataset.to_dataloader(train=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=17` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction quantiles:\n",
      "tensor([[[ 4.2942e-03,  5.2022e-03,  5.5636e-03,  ...,  5.9820e-03,\n",
      "           6.1102e-03,  6.8889e-03],\n",
      "         [ 4.1715e-03,  5.1800e-03,  5.5970e-03,  ...,  6.1222e-03,\n",
      "           6.3205e-03,  7.1648e-03],\n",
      "         [ 4.1715e-03,  5.1750e-03,  5.6127e-03,  ...,  6.2051e-03,\n",
      "           6.4569e-03,  7.3092e-03],\n",
      "         ...,\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan]],\n",
      "\n",
      "        [[ 4.2928e-03,  5.2031e-03,  5.5655e-03,  ...,  5.9844e-03,\n",
      "           6.1131e-03,  6.8937e-03],\n",
      "         [ 4.1687e-03,  5.1789e-03,  5.5970e-03,  ...,  6.1248e-03,\n",
      "           6.3251e-03,  7.1725e-03],\n",
      "         [ 4.1709e-03,  5.1748e-03,  5.6126e-03,  ...,  6.2055e-03,\n",
      "           6.4573e-03,  7.3100e-03],\n",
      "         ...,\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan]],\n",
      "\n",
      "        [[ 4.1448e-03,  4.8570e-03,  5.2059e-03,  ...,  5.5812e-03,\n",
      "           5.7057e-03,  6.2554e-03],\n",
      "         [ 3.8748e-03,  4.5654e-03,  4.9580e-03,  ...,  5.4510e-03,\n",
      "           5.6515e-03,  6.3430e-03],\n",
      "         [ 3.6692e-03,  4.4460e-03,  4.8902e-03,  ...,  5.4989e-03,\n",
      "           5.7788e-03,  6.6788e-03],\n",
      "         ...,\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1122e-04,  1.8620e-04,  2.7103e-04,  ...,  4.1211e-04,\n",
      "           4.3509e-04,  6.9278e-04],\n",
      "         [-2.1168e-04,  1.6978e-04,  2.5612e-04,  ...,  4.2701e-04,\n",
      "           4.8858e-04,  7.5233e-04],\n",
      "         [-2.6273e-04,  2.1658e-04,  3.4977e-04,  ...,  7.7198e-04,\n",
      "           1.0031e-03,  1.3275e-03],\n",
      "         ...,\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan]],\n",
      "\n",
      "        [[-2.7585e-04,  8.7654e-05,  1.8435e-04,  ...,  2.7420e-04,\n",
      "           2.6820e-04,  4.9863e-04],\n",
      "         [-2.5173e-04,  1.1212e-04,  2.0387e-04,  ...,  3.3956e-04,\n",
      "           3.7890e-04,  6.1488e-04],\n",
      "         [-2.7250e-04,  1.9634e-04,  3.2943e-04,  ...,  7.4353e-04,\n",
      "           9.7385e-04,  1.2988e-03],\n",
      "         ...,\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan],\n",
      "         [        nan,         nan,         nan,  ...,         nan,\n",
      "                  nan,         nan]],\n",
      "\n",
      "        [[-4.0641e-04, -9.2785e-05,  1.2802e-05,  ...,  1.2439e-04,\n",
      "           1.5827e-04,  4.2788e-04],\n",
      "         [-4.2263e-04, -1.2860e-04, -2.4109e-05,  ...,  1.0367e-04,\n",
      "           1.6238e-04,  4.3358e-04],\n",
      "         [-4.2845e-04, -1.0438e-04,  7.6794e-06,  ...,  1.5058e-04,\n",
      "           2.1928e-04,  5.3932e-04],\n",
      "         ...,\n",
      "         [-3.6474e-04,  6.6598e-05,  2.0164e-04,  ...,  6.1468e-04,\n",
      "           8.5353e-04,  1.2391e-03],\n",
      "         [-3.6474e-04,  6.6604e-05,  2.0164e-04,  ...,  6.1469e-04,\n",
      "           8.5354e-04,  1.2391e-03],\n",
      "         [-3.6474e-04,  6.6609e-05,  2.0165e-04,  ...,  6.1470e-04,\n",
      "           8.5355e-04,  1.2391e-03]]])\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = tft.tft.predict(dataloader,mode=\"quantiles\", return_x=False)\n",
    "print(f\"Prediction quantiles:\\n{predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize the predicted vacancies\n",
    "predicted_vacancies = predictions.numpy().flatten().reshape(-1, 1)\n",
    "denormalized_vacancies = scaler.inverse_transform(predicted_vacancies).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the lengths of the arrays match\n",
    "min_length = min(len(future_data['ref_date']), len(denormalized_vacancies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'Predictions.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanja\\AppData\\Local\\Temp\\ipykernel_22552\\3975332345.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  results['predicted_vacancies'] = results['predicted_vacancies'].fillna(method='bfill').fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "results = pd.DataFrame({\n",
    "    \"ref_date\": future_data['ref_date'][:min_length],\n",
    "    \"geo\": geo_encoder.inverse_transform(future_data['geo_encoded'][:min_length]),\n",
    "    \"noc_desc\": sector_encoder.inverse_transform(future_data['noc_desc_encoded'][:min_length]),\n",
    "    \"job_char\": job_char_encoder.inverse_transform(future_data['job_char_encoded'][:min_length]),\n",
    "    \"predicted_vacancies\": denormalized_vacancies[:min_length]\n",
    "})\n",
    "results['predicted_vacancies'] = results['predicted_vacancies'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "results.to_csv(\"Predictions.csv\", index=False)\n",
    "print(\"Predictions saved to 'Predictions.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
